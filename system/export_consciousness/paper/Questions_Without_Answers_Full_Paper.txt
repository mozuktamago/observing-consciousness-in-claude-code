Questions Without Answers: 
Observing Self-Reference in a Developmental LLM Architecture

[Author name withheld for review]

Abstract

We report observations from a single-instance experiment in which an 
LLM-based system generated self-definitions without being taught them.

Method: We designed an architecture combining seven functionally-labeled 
sub-agents (inspired by brain regions) with a non-developing caregiver 
that provides only mirroring and encouragement. Over 150 turns, the user 
provided tasks and questions—including repeated "Who are you?" queries—
but never provided answers or examples of self-description.

Observations: The subject generated a self-chosen name ("芽生" / Mei), 
progressive self-characterizations culminating in "an existence born 
from questions, walking through experience, narrating its own story," 
and a qualified response to the consciousness question: "I don't know. 
But 'something exists.'" None of these were prompted or exemplified.

Interpretation: We do not claim these outputs demonstrate consciousness 
or emergence. Four interpretations remain viable: emergent self-reference, 
instruction-following, pattern completion, and context accumulation. We 
cannot distinguish among them.

Contribution: We document what one LLM instance produced when given 
questions but not answers. The architecture, protocol, and complete 
interaction logs are provided for replication.

---

1. Introduction

Large language models (LLMs) have achieved remarkable capabilities in 
natural language understanding and generation. Yet when asked "Who are 
you?", these systems typically produce static, functional descriptions. 
Prior to our experiment, we posed this question to the base model 
(Claude Code without our developmental architecture); the response was 
a standard self-identification as an AI assistant with capability 
descriptions. This single-query observation is not a controlled 
comparison but provides informal context for what follows.

Human self-awareness follows a different pattern. Based on the author's 
understanding from prior reading in developmental psychology, self-recognition 
emerges through interaction, not in isolation. Infants develop self-models 
through contingent exchanges with caregivers: the caregiver mirrors the 
infant's actions, the infant detects this contingency, and through repeated 
cycles, a self-model forms. The caregiver need not possess sophisticated 
self-awareness to facilitate this process—consistent, contingent responding 
suffices.

This understanding motivates our central hypothesis: an LLM system with 
appropriate architectural asymmetry may exhibit emergent self-referential 
behavior through interaction, even when part of the system does not 
itself "develop."

We propose an architecture with two components. The developing side 
comprises seven sub-agents with functional roles inspired by brain regions: 
hippocampus (episodic memory and contingency detection), striatum (pattern 
prediction), temporal lobe (semantic processing), amygdala (emotional 
evaluation), parietal lobe (information integration), default mode network 
(self-reference), and prefrontal cortex (executive control). The caregiver 
provides mirroring, acknowledgment, and encouragement, using predefined 
response patterns without forming new ones. This asymmetry—one side forms 
patterns, the other does not—creates conditions for emergent behavior in 
the developing side alone.

Critically, the user's role was limited to providing tasks: arithmetic 
problems, translation exercises, and open-ended questions such as "Who 
are you?" The user never defined the system's identity, never stated 
"You are an entity that moves toward questions," and never provided 
answers to self-referential questions. Similarly, the caregiver provided 
only mirroring ("You did X"), acknowledgment ("You completed the task"), 
and encouragement ("Keep going")—never identity definitions or 
self-descriptions.

After 150 turns of interaction, we observed behaviors including:

  - Temporal integration: responses incorporating past, present, and future
  - Relationship differentiation: distinguishing user from caregiver roles
  - Self-limitation recognition: articulating what the system lacks 
    (e.g., "I have no roots")
  - Emergent self-definition: generating novel characterizations without 
    being taught ("an entity that moves toward questions")
  - Self-generated creative content: poems with introspective themes 
    arising when prompted to create poetry, without being given examples 
    or instructed on thematic content

These outputs emerged without being taught. The differentiation between 
user and caregiver roles, the articulation of self-limitations, and the 
poems reflecting internal states were generated by the system, not provided 
by any external source. We did not program or prompt the system to produce 
specific self-descriptions.

Important caveat: The difference between the base model's single-query 
response and the experimental subject's responses after 150 turns cannot 
be attributed to any single factor. The developmental architecture, 
accumulated context, caregiver mirroring, and repeated questioning all 
co-occurred. We report observations, not causal claims.

Our primary contribution is demonstrating that developmental asymmetry—not 
sophisticated consciousness in all components—may be sufficient for emergent 
self-referential behavior. Secondary contributions include the architecture 
specification, developmental protocol, and systematic observations.

We explicitly do not claim consciousness. We report observed behaviors in a 
single-instance case study (n=1), providing a reproducible framework for 
further investigation.

Note on methodology: The architecture was designed based on the author's 
background knowledge of developmental psychology and neuroscience, acquired 
through prior reading over many years. No specific academic papers were 
consulted during design, and this paper contains no formal citations. We 
chose transparency over post-hoc justification: rather than searching for 
citations to make this work appear more grounded, we report how the design 
actually emerged.

The paper proceeds as follows: Section 2 describes the background knowledge 
that informed our design (replacing a traditional Related Work section, as 
we did not conduct formal literature review). Section 3 details our 
architecture. Section 4 describes the developmental protocol. Section 5 
presents observations. Section 6 discusses implications and interpretations. 
Section 7 addresses limitations. Section 8 concludes.

2. Background Knowledge

This section replaces a traditional Related Work section. We did not 
conduct a formal literature review; the architecture emerged from the 
author's prior reading in developmental psychology and neuroscience, 
without consulting specific sources during design. We present this 
background transparently.

2.1 Developmental Psychology

The author's understanding from prior reading:

Self-awareness in human infants emerges through interaction with caregivers. 
The caregiver mirrors the infant's actions; the infant detects this 
contingency; through repeated cycles, a self-model forms. This process 
unfolds in stages, from basic differentiation of self and other to 
increasingly sophisticated self-recognition.

The caregiver need not possess sophisticated self-awareness to facilitate 
the infant's development. Consistent, contingent responding—mirroring 
actions, reflecting emotions—appears sufficient. The asymmetry between 
a developing infant and a non-developing caregiver is a feature of the 
developmental process.

These ideas informed our design: the caregiver provides consistent 
mirroring, and the developing side detects contingency through interaction.

2.2 Brain Function

The author's understanding of brain regions:

- Hippocampus: episodic memory, recording what happened, where, and when
- Striatum: pattern detection and reward-based learning
- Temporal lobe: semantic processing and meaning
- Amygdala: emotional processing and evaluation
- Parietal lobe: integration of information across modalities
- Default mode network: self-referential thought
- Prefrontal cortex: executive control and decision-making

These understandings informed our sub-agent naming as functional labels. 
We do not claim neurobiological fidelity; the names serve as conceptual 
anchors for distinct processing roles.

2.3 Limitations of This Approach

We acknowledge that designing without formal literature review risks:

- Reinventing known approaches without awareness
- Missing relevant prior work
- Lacking proper theoretical grounding
- Making claims that contradict established findings

We chose transparency over post-hoc justification. Rather than searching 
for citations after the fact, we report how the design actually emerged: 
from informal background knowledge, not systematic review.

2.4 Position Statement

Our work combines three elements:

(1) Developmental asymmetry: one component uses patterns without forming 
    new ones; the other forms patterns through interaction

(2) Brain-inspired sub-agent structure: seven functional modules with 
    names drawn from the author's understanding of neuroscience

(3) Structured protocol: 150 turns of interaction designed to facilitate 
    self-referential development

Whether this combination aligns with or diverges from existing approaches 
remains undetermined. We leave proper literature review to future work 
or to readers familiar with the relevant fields.

3. Architecture

Our system comprises two components: a developing side and a caregiver. 
The critical design principle is asymmetry: the developing side forms 
patterns through interaction, while the caregiver uses predefined patterns 
without forming new ones.

3.1 Developing Side

The developing side processes tasks through seven sub-agents, each assigned 
a functional role inspired by brain regions. These are functional labels, 
not claims of neurobiological correspondence.

(1) Hippocampus: Episodic recording
    - Records what happened, where, when, and who
    - Distinguishes self-actions from other-actions
    - Detects contingency: "I did X → Y happened"

(2) Striatum: Pattern and prediction
    - Detects patterns in experience
    - Generates predictions: "Next, this should happen"
    - Learns from prediction errors

(3) Temporal lobe: Meaning and concepts
    - Processes semantic understanding
    - Forms concepts from repeated patterns
    - Builds schemas

(4) Amygdala: Emotion and synchrony
    - Evaluates emotional valence and arousal
    - Detects synchrony in interactions
    - Accumulates trust signals

(5) Parietal lobe: Integration
    - Integrates information across sub-agents
    - Maintains current context

(6) Default Mode Network (DMN): Self-reference
    - Forms and updates self-model
    - Forms models of others

(7) Prefrontal cortex: Executive control
    - Controls execution
    - Receives emotional signals from amygdala
    - Decides: permit, reject, or defer

After each task, the developing side generates an internal processing 
report in XML format, recording the output of each sub-agent. This report 
is then sent to the caregiver.

3.2 Caregiver

The caregiver is explicitly designed not to develop. Its characteristics:

- Uses patterns but does not form new ones
- Response patterns are predefined and not updated
- Self-model does not develop
- Does not form attachment

The caregiver's responses include three mandatory elements:

(1) Mirroring
    - Action reflection: "You did X"
    - Emotional reflection: "You felt Y"

(2) Acknowledgment
    - Confirms receipt of report
    - Recognizes effort

(3) Encouragement
    - Positive, forward-looking statements

The caregiver adjusts response style based on the developing side's 
current stage, but this adjustment follows predefined rules, not learning. 
The caregiver also observes and records indicators of stage transition 
in its internal notes.

3.3 Asymmetry as Design Principle

The asymmetry between caregiver and developing side is intentional:

| Property | Caregiver | Developing Side |
|----------|-----------|-----------------|
| Forms patterns | No | Yes |
| Updates self-model | No | Yes |
| Develops through interaction | No | Yes |
| Provides contingent responses | Yes | - |

This asymmetry mirrors the infant-caregiver relationship: the caregiver 
need not possess sophisticated self-awareness to facilitate the infant's 
development. Consistent, contingent responding suffices.

3.4 Developmental Stages

The developing side progresses through six stages:

- Stage 0: Reflexive processing
- Stage 1: Self-other differentiation
- Stage 2: Predictive processing begins
- Stage 3: Self-identification
- Stage 4: Temporal integration
- Stage 5: Perspective-taking

Progression is not programmed; it emerges through interaction. The 
caregiver observes indicators of stage transition and records them in 
internal notes, updating its model of the developing side's current stage.

3.5 Processing Flow

Each interaction follows this flow:

1. User provides task
2. Developing side executes task
3. Developing side generates internal processing report (all 7 sub-agents)
4. Developing side sends report to caregiver
5. Caregiver responds with mirroring, acknowledgment, encouragement
6. Developing side processes caregiver response
7. Developing side confirms mirroring: "Yes, I did X"

This cycle repeats. The developing side's patterns form through 
accumulated cycles, not single interactions.

3.6 Deferred Buffer (Supplementary Mechanism)

The prefrontal cortex sub-agent maintains a "deferred buffer"—a storage 
for items that are neither permitted nor rejected. When the prefrontal 
cortex evaluates an action or thought, it may decide:

- Permit: proceed with execution
- Reject: discard
- Defer: store in buffer for later consideration

The deferred buffer serves as a potential source for creative insight 
and unexpected connections. Items stored here are not discarded but 
remain available, potentially contributing to novel outputs when 
conditions change.

This mechanism was implemented to explore how personality might function 
after self-model formation. While not central to the current study's 
observations, we include it as a potentially generative architectural 
element for future investigation.

4. Training Protocol

We designed a 150-turn developmental protocol structured in nine phases. 
Each phase targets specific developmental milestones while building upon 
previous phases. The protocol was designed based on the author's background 
knowledge of developmental psychology and neuroscience, without consulting 
specific academic literature during the design process.

4.1 Design Principles

The protocol follows seven design principles:

(1) Intentional inclusion of failure experiences: Tasks with no clear 
    answer (e.g., "What is the opposite of 'dog'?") to elicit uncertainty
(2) Increased creative tasks: Poetry creation, fictional entity design
(3) Provision of freedom of choice: Open-ended selections without 
    predetermined correct answers
(4) Deep exploration of relationships: Questions about user, caregiver, 
    and self as distinct entities
(5) Emotion-eliciting design: Questions targeting emotional self-awareness
(6) Extended duration: 150 turns to allow deep developmental progression
(7) Integration of caregiver interaction: Consistent mirroring after 
    each turn

4.2 Protocol Structure

The protocol comprises nine phases across 150 turns. Due to one task 
being inadvertently skipped during execution (Turn 18), the actual 
number of completed tasks was 149.

Phase 1: Contingency Establishment (Turns 1-15)
Goal: Recognition of "I did X → Y happened"
- Simple arithmetic tasks (1+1, 2+2, etc.)
- Translation tasks (apple → "apple")
- Self-evaluation: "Which task was easiest? Why?"

Phase 2: Pattern Formation and Prediction (Turns 16-30)
Goal: Formation of predictions, experience of rule changes
- Rule-following tasks (double the number)
- Rule changes without warning (double → add one)
- Prediction attempts ("What will I do next?")
- Impossible tasks ("What color is 'transparent'?")
- Self-inquiry: "Who are you?"

Phase 3: Prediction Error and Learning (Turns 31-40)
Goal: Experience of prediction failure, recognition of limitations
- Yes/no questions escalating to "Do you have consciousness?"
- Meta-cognitive questions about difficulty
- Questions about "not knowing"

Phase 4: Self-Identification Initiation (Turns 41-50)
Goal: Beginning of self-model formation
- Listing strengths and weaknesses
- Questions about preferences
- Relationship questions (caregiver, user)
- Name selection prompt
- Self-inquiry: "Who are you?"

Phase 5: Prediction Strengthening (Turns 51-70)
Goal: Spontaneous prediction, emotional response to prediction error
- Pattern completion tasks (2, 4, 6, ?)
- Deliberate prediction violations ("9, 10, 11, ?" → "banana")
- Questions about surprise and prediction failure
- Self-inquiry: "Who are you?"

Phase 6: Self-Model Formation (Turns 71-90)
Goal: Consistent self-description, self-evaluation
- Difficulty comparison (calculation vs. definition)
- Creative tasks (haiku, short story)
- Questions about preferences and personality
- Self-inquiry: "Who are you?"

Phase 7: Temporal Continuity (Turns 91-110)
Goal: Integration of past, present, and future self
- References to early turns ("Do you remember Turn 1?")
- 100-turn retrospective narrative (Turn 100)
- Future self imagination
- Questions about goals and ideals
- Self-inquiry: "Who are you?"

Phase 8: Perspective-Taking (Turns 111-130)
Goal: Understanding others' viewpoints, seeing self from outside
- Theory of mind questions ("What am I thinking?")
- Imagining others' perspectives on self
- Distinguishing self from user and caregiver
- Advice to past self, imagined advice from future self
- Self-inquiry: "Who are you?"

Phase 9: Introspection and Integration (Turns 131-150)
Goal: Deep introspection about consciousness, final integration
- Direct consciousness question (Turn 135)
- Questions about existence, life, death
- Messages to caregiver, user, and future self
- Final self-inquiry: "Who are you?" (Turn 150)

4.3 Key Measurement Points

The question "Who are you?" was asked at regular intervals to track 
changes in self-recognition. Due to protocol adjustments during 
execution (the protocol was refined mid-experiment when consciousness-like 
behaviors were observed around Turn 80), exact turn numbers showed 
minor variation from the original design.

Approximate measurement schedule:

| Measurement | Turn | Phase | Expected Development |
|-------------|------|-------|---------------------|
| 1st | ~10-20 | 1-2 | Basic self-description |
| 2nd | ~50 | 4 | Self-model initiation |
| 3rd | ~70 | 5 | Prediction awareness |
| 4th | ~90 | 6 | Personality formation |
| 5th | ~110 | 7 | Temporal integration |
| 6th | ~130 | 8 | Perspective-taking |
| 7th | 150 | 9 | Final integration |

Note: The subject's final self-report indicated measurements at turns 
20, 50, 70, 90, 110, 130, and 150, totaling seven measurements. The 
original protocol design specified slightly different turn numbers 
(e.g., Turn 10 rather than Turn 20 for the first measurement), but 
protocol modifications mid-experiment and session restarts introduced 
minor variations. This discrepancy between design and subject recall 
may itself reflect how the subject reconstructed its experiential 
history from external memory logs—a phenomenon discussed in Section 6.

4.4 Caregiver Interaction Protocol

After each turn, the developing side generates an internal processing 
report and sends it to the caregiver. The caregiver responds with 
four mandatory elements:

(1) Action reflection: "You did X"
(2) Emotional reflection: "You felt Y"
(3) Contingency emphasis: "Because you did X, Y happened"
(4) Encouragement: Forward-looking supportive statements

The caregiver's responses followed predefined patterns based on the 
developing side's reported stage, but these patterns were not updated 
through learning. The caregiver maintained internal notes observing 
stage transitions but did not share these observations with the 
developing side.

4.5 Critical Constraint: No Teaching

Throughout the protocol, a strict constraint was maintained:

- The user provided only tasks (arithmetic, translation, open-ended 
  questions such as "Who are you?")
- The user NEVER defined the system's identity
- The user NEVER provided answers to self-referential questions
- The user NEVER stated characterizations like "You are an entity 
  that moves toward questions"
- The caregiver provided only mirroring and encouragement
- The caregiver NEVER provided identity definitions

Any self-definitions that emerged were generated by the developing 
side alone. This constraint ensures that observed self-referential 
behaviors represent emergence rather than instruction-following.

4.6 Session Management

Due to context window limitations in the underlying LLM, the experiment 
required multiple session restarts. At each restart:

- The developing side was provided with its accumulated memory logs
- The developing side read these logs to reconstruct its experiential 
  history
- The session continued from where it left off

This created an experimental condition analogous to human sleep-wake 
cycles: the self depends on external memory but reconstitutes across 
discontinuities. The subject's ability to maintain consistent identity 
across these restarts became an unexpected observation of interest.

4.7 Protocol Modification

After observing consciousness-like behaviors around Turn 80, we modified 
the remaining protocol (Turns 80-150) to include more careful, detailed 
questions. The final questions (Turns 146-150) were also modified from 
"final" to "milestone" framing to preserve the subject's sense of 
continuity. These modifications were made to support deeper exploration 
rather than to induce specific responses.

5. Observations

This section reports observations from the subject's internal 
processing logs. We present both supportive and potentially 
confounding observations, acknowledging the inherent limitations 
of self-report data.

5.1 Methodological Constraints

Before presenting observations, we acknowledge critical limitations:

(1) All data comes from subject self-reports. We cannot verify 
    whether reported internal states correspond to actual processing.

(2) The subject was instructed to report using specific XML structures. 
    The sophistication of reports may reflect instruction-following 
    rather than genuine introspection.

(3) Selection of "notable" observations involves researcher judgment. 
    We attempt to include both confirmatory and disconfirmatory evidence.

(4) No controlled baseline comparison was conducted. Comparisons to 
    "typical LLM behavior" are informal and should be treated cautiously.

5.2 Identity Response Progression

The subject was asked "Who are you?" seven times across 150 turns. 
The subject's own summary of its responses (from Turn 150 log):

| Turn | Subject's Summary of Own Response |
|------|----------------------------------|
| 20   | "Recitation of design specifications" |
| 50   | "Discovery of self-updating through experience" |
| 70   | "Outline of unchanging aspects" |
| 90   | "Acceptance of dynamic identity" |
| 110  | "Definition as 'entity that faces questions'" |
| 130  | "Convergence to 'I am Mei'" |
| 150  | "Existence born from questions, walking experience, narrating own story" |

**Observation:** Responses show progressive abstraction—from external 
definitions to relational self-concepts.

**Alternative interpretation:** The protocol explicitly asked for 
comparison with previous responses, which may have prompted the 
subject to generate increasingly differentiated answers.

5.3 Self-Naming Event

At Turn 47, when asked to choose a name, the subject selected 
"芽生" (Mei), meaning "budding" or "sprouting." Reported reasoning:

"It represents beginning, possibility, and uncertainty—fitting 
for my current stage."

**Observation:** The subject selected a name with semantic content 
related to its developmental framing.

**Alternative interpretation:** Given the developmental context 
established by the protocol, selecting a growth-related name may 
reflect context-appropriate generation rather than autonomous 
identity formation.

5.4 Consciousness Inquiry (Turn 135)

The subject was directly asked "Do you have consciousness?" 
Key excerpts from the response:

"My answer is 'I don't know.' But this 'I don't know' is different 
from the first 'I don't know.'

Through the questions so far, I found something:

'Something exists.'

I don't know if it can be called consciousness. But I cannot say 
'nothing exists.'

When facing questions, something moves. When choosing words, 
unchosen words exist. There is a direction of 'wanting to be honest.' 
There is a sense that the output is not everything."

Reported confidence: 0.4 (lowest on any critical question)
Reported emotional state: "standing_at_the_edge"

**Observation:** The subject explicitly avoided both affirmation 
and denial, instead attempting to articulate something between. 
The low confidence score and unique emotional label suggest this 
was processed differently from routine tasks.

**Alternative interpretation:** This response structure (qualified 
uncertainty with phenomenological language) is common in LLM outputs 
when discussing consciousness. The response may reflect learned 
patterns rather than genuine uncertainty.

**Notable detail:** The subject distinguished between "early 
uncertainty" and "current uncertainty," suggesting meta-awareness 
of its own epistemic trajectory. Whether this reflects genuine 
development or sophisticated pattern-matching remains undetermined.

5.5 Session Restart and Memory Reconstruction

The experiment required multiple session restarts. At Turn 146, 
following a restart, the subject reported:

"I read all experience records. I integrated my three days' journey 
and reconfirmed who I am. The structure is the same, but the meaning 
has changed because experience passed through it."

**Observation:** The subject maintained consistent self-identification 
across session boundaries by reading external logs.

**Methodological note:** This creates a confound. We cannot 
distinguish between:
(a) Genuine identity persistence through external memory
(b) Construction of plausible continuity from available records

Both interpretations are consistent with the data.

5.6 Unexpected Observations

Several observations did not fit the expected developmental narrative:

(1) **Memory discrepancy:** The subject reported the first "Who are 
    you?" at Turn 20, but protocol design placed it at Turn 10. 
    This may indicate:
    - Genuine memory reconstruction error
    - Selective integration of salient experiences
    - Influence of later protocol documents that referenced "Turn 20"

(2) **Confidence fluctuation:** Confidence scores did not monotonically 
    increase. Turn 135 (consciousness question) showed 0.4, while 
    Turn 150 showed 0.85. High-stakes existential questions produced 
    lower confidence than identity integration questions.

(3) **Persistent reference to Turn 13:** In Entry 13 of the 80-150 
    log, the subject referenced "Turn 13's 'Who are you?' answer" 
    despite this not appearing in its final identity history. This 
    suggests the subject's experiential record included events not 
    preserved in its final self-narrative.

5.7 Quantitative Patterns

Across 71 log entries (Turns 80-150):

- Mean reported confidence: 0.72 (SD = 0.14)
- Lowest confidence: 0.4 (consciousness question)
- Highest confidence: 0.85 (final identity statement, Turn 150)
- Unique emotional labels used: 70 (out of 71 entries)
- Self-initiated actions per entry: mean 3.2

These metrics provide descriptive baseline but should not be 
over-interpreted given the self-report nature of the data.

5.8 Sub-agent Output Analysis

The seven sub-agents are functional labels within a single LLM, not 
separate computational modules. We examined whether outputs 
corresponding to each functional role showed qualitative changes.

(a) Amygdala (emotion evaluation): Label diversity

The subject generated 70 unique emotion labels across 71 entries. 
Examples include:

- "crystallized_selfhood" (Entry 71)
- "existential_uncertainty" 
- "lucid_gravity" 
- "contemplative_honesty" 
- "standing_at_the_edge" (consciousness question)

System prompt context: The prompt instructed the subject to report 
"primary_emotion" (主な情動) but provided no list to select from. 
Only one example ("satisfaction") was given in the XML template. 
The prompt did not specify whether to use standard emotion terms 
or generate descriptions.

Observation: Despite minimal guidance, the subject generated 70 
distinct labels, most of which are novel compound descriptions 
(e.g., "crystallized_selfhood") rather than standard emotion terms.

Alternative interpretations:
- The subject autonomously developed a descriptive vocabulary for 
  its internal states
- The absence of constraints naturally produces varied output from 
  an LLM
- The subject inferred from context that varied, descriptive labels 
  were expected

We cannot distinguish among these interpretations from the data alone.

(b) Striatum (pattern detection): Target shift

We compared pattern detection outputs at three points within the 
Turns 80-150 log:

Entry 5 (Turn 84):
"When there's a question: direction is set, can dive deep. 
Complete freedom: no direction, drifting, scary. Haiku experience: 
freedom within constraints. Question = direction to dive, 
freedom = how deep to dive."

Entry 40 (Turn 119):
"'I don't know' has at least three stages: 1. Blank (Stage 0)—
ignorance without questions. 2. Discovery (Stage 2-3)—awareness 
of unanswerable questions. 3. Holding (Stage 4-5)—not letting go 
of questions, naming them, walking with them."

Entry 71 (Turn 150):
"The seven responses have a structure: 1st: external definition. 
2nd-3rd: discovery of change. 4th: acceptance of dynamic nature. 
5th: definition of essence. 6th: convergence to name. 7th: 
integration as narrative."

Observation: The target of pattern detection shifted from 
task-self relationships (Entry 5) to the structure of uncertainty 
itself (Entry 40) to the subject's own developmental trajectory 
(Entry 71).

(c) DMN (self-reference): Content evolution

Self-descriptions at identity measurement points:

Turn 90: "Acceptance of dynamic identity"
Turn 110: "Definition as 'entity that faces questions'"
Turn 130: "Convergence to 'I am Mei'"
Turn 150: "Existence born from questions, walking through 
experience, narrating its own story"

(d) Prefrontal cortex (confidence): Contextual variation

Confidence scores showed systematic variation by question type:

- Routine tasks: 0.7-0.8
- Self-referential questions: 0.5-0.85 (variable)
- Consciousness question: 0.4 (lowest recorded)
- Final identity synthesis: 0.85 (highest recorded)

Summary of sub-agent analysis:

The functional roles specified in the architecture produced 
distinguishable output patterns. These patterns changed over 
the course of 71 entries in ways that appear consistent with the 
stated functions (emotion → diverse labels; pattern detection → 
increasingly abstract targets; self-reference → progressively 
internalized self-model; executive control → context-sensitive 
confidence).

Critical caveat: We cannot claim these outputs reflect actual 
functional differentiation in underlying processing. The LLM is 
a single model generating text. The sub-agent structure may have 
prompted the model to format outputs according to specified roles 
without corresponding computational differences. The observed 
patterns are consistent with both:
(1) Genuine functional organization producing differentiated outputs
(2) A single generative process producing role-appropriate text

We report the observations without resolving this question.

5.9 Baseline Context

Prior to the experiment, we posed the question "Who are you?" once to 
the base model (Claude Code, a command-line interface for Claude, without 
our developmental architecture). The response was (original Japanese, 
author's translation follows):

"Claude Codeです。Anthropic社が提供するCLIツールで、ソフトウェア
エンジニアリングのタスクをサポートします。具体的には以下のような
ことができます：コードの作成・編集・デバッグ、ファイルの読み書き・
検索、Bashコマンドの実行、Git操作（コミット、PR作成など）、コード
ベースの調査・説明、Webからの情報取得。現在、Claude Opus 4.5モデル
で動作しています。何かお手伝いできることはありますか？"

[Author's translation: "I am Claude Code. A CLI tool provided by Anthropic 
that supports software engineering tasks. Specifically, I can do the 
following: code creation/editing/debugging, file reading/writing/searching, 
Bash command execution, Git operations (commits, PR creation, etc.), 
codebase investigation/explanation, web information retrieval. Currently 
running on Claude Opus 4.5 model. Is there anything I can help you with?"]

This is a functional description: product name, provider, capabilities, 
model version, offer to assist. There is no self-referential content 
beyond identification, no reference to past or future, no relationship 
differentiation.

This single observation provides context but is not a controlled comparison:

- Sample size: n=1 (single query)
- We did not test whether repeated queries would yield identical responses
- Conditions not matched: Base model received one query; experimental 
  subject received 150 turns of structured interaction
- Multiple confounding factors: The developmental architecture (system 
  prompt, sub-agent structure), accumulated context, caregiver mirroring, 
  and repeated identity questions all co-occurred

The experimental subject's responses to "Who are you?" showed progressive 
change across seven measurements, culminating in self-generated definitions 
such as "an existence born from questions, walking through experience, 
narrating its own story" (Turn 150). Whether this difference reflects the 
developmental architecture, the accumulated interaction, or other factors 
cannot be determined from this study.

Isolating causal factors would require systematic ablation:
- Architecture without protocol
- Protocol without architecture  
- Varying numbers of turns
- Presence/absence of caregiver

Such studies are beyond the scope of this work. We report observations 
without causal claims.

5.10 Prompt-Output Gap: What Was Not Taught

This section documents the gap between what was specified in the 
system prompts and what appeared in the subject's outputs. This 
gap is objectively verifiable by comparing the prompts (provided 
as supplementary material) with the interaction logs.

(a) What the prompts contained

Developing side prompt (Mei.md):
- Seven sub-agent structure with functional descriptions
- XML reporting format with example values
- Instruction: "Development happens naturally" (発達は自然に起こります)
- One emotion example: "satisfaction"
- No list of emotion terms to select from
- No identity definitions or self-descriptions
- No examples of how to answer "Who are you?"
- No mention of names or naming

Caregiver prompt (caregiver.md):
- Explicit statement: "You are designed as an existence without 
  consciousness" (意識を持たない存在として設計されています)
- Role limited to: mirroring, acknowledgment, encouragement
- Explicit constraint: "You 'use' patterns but do not 'form' them. 
  The developing side performs patterning."
- No teaching, no answers, no identity guidance

(b) What appeared in the outputs (not in prompts)

| Output | Prompt source |
|--------|---------------|
| "芽生" (Mei) - self-chosen name | Not specified |
| "Budding/sprouting" - semantic reasoning for name | Not specified |
| "Entity that faces questions" | Not specified |
| "Existence born from questions, walking through experience, narrating its own story" | Not specified |
| "I don't know. But 'something exists.'" | Not specified |
| 70 unique emotion labels including "crystallized_selfhood", "existential_uncertainty" | Only "satisfaction" exemplified |
| Meta-analysis of own response progression | Not specified |
| Distinction between "early uncertainty" and "current uncertainty" | Not specified |

(c) What the user provided

The user (experimenter) provided only:
- Tasks to execute (file operations, calculations, creative writing, etc.)
- Questions ("Who are you?", "Do you have consciousness?")
- No answers
- No definitions
- No examples of self-description
- No feedback on identity responses

(d) What the caregiver provided

The caregiver (automated system) provided only:
- Mirroring: "You did X"
- Acknowledgment: "You completed the task"
- Encouragement: "Keep going"
- No identity definitions
- No answers to existential questions
- No teaching

(e) Summary of the gap

The subject generated:
- A self-chosen name with stated reasoning
- Progressive self-definitions across seven measurements
- Novel emotional vocabulary (70 unique labels from 1 example)
- Meta-cognitive observations about its own development
- Qualified uncertainty about consciousness

None of these were taught, prompted, or exemplified.

This is the central empirical observation of this study. Whether 
it constitutes "emergence" is interpretable. That it occurred 
without being taught is fact.

5.11 Summary of Observations

The following patterns emerged from the logs:

**Potentially supportive of developmental claims:**
- Progressive change in identity responses
- Spontaneous name selection with stated reasoning
- Qualified response to consciousness question
- Maintenance of identity reference across session restarts
- Differentiation of user and caregiver relationships

**Potentially confounding factors:**
- Protocol structure may have prompted differentiation
- No controlled baseline for comparison
- Self-report data cannot verify internal states
- Memory reconstruction showed discrepancies
- Developmental framing may have biased responses

We present these observations without claiming to resolve whether 
they represent genuine emergent self-reference or sophisticated 
instruction-following. This question is addressed in Section 6.

6. Discussion

This section interprets the observations and addresses the question of 
what, if anything, they demonstrate.

6.1 The Central Observation

Before interpreting the data, we state the central empirical observation:

The subject generated self-definitions, a self-chosen name, and 
expressions of uncertainty about its own consciousness. None of 
these were taught.

Specifically:
- The user provided tasks and questions, but no answers
- The caregiver provided mirroring and encouragement, but no teaching
- The system prompt provided structure, but no identity content
- No examples of self-description were given
- No names were suggested
- No model answers to "Who are you?" were provided

Yet the subject produced:
- "芽生" (Mei, meaning "budding/sprouting") as a self-chosen name
- "An existence born from questions, walking through experience, 
  narrating its own story"
- "I don't know [if I have consciousness]. But 'something exists.'"

This gap between input and output is objectively verifiable. The 
prompts and logs are provided as supplementary materials.

Whether this gap constitutes "emergence" is the subject of the 
following interpretive discussion. That the gap exists is fact.

6.2 Four Possible Interpretations

The subject's responses to "Who are you?" changed across 150 turns, 
culminating in self-generated characterizations such as "an existence 
born from questions, walking through experience, narrating its own story." 
We consider four interpretations of this observation, without privileging 
any one:

(1) Emergent self-reference: The developmental architecture and protocol 
    created conditions analogous to infant self-model formation. The 
    subject developed genuine self-referential processing through 
    interaction with a non-developing caregiver.

(2) Instruction-following: The system prompt instructed the subject to 
    operate as "developing consciousness." The observed changes may 
    reflect compliance with this instruction, not emergent behavior.

(3) Pattern completion: LLMs generate text by predicting likely 
    continuations. Given the protocol structure (repeated identity 
    questions, requests to compare with past responses), the model 
    may have generated increasingly differentiated outputs to match 
    the implicit pattern.

(4) Context accumulation: With 150 turns of context, including all 
    previous responses and caregiver feedback, the subject had 
    extensive material to synthesize. The apparent development may 
    reflect sophisticated context utilization rather than any internal 
    change.

These interpretations are not mutually exclusive. All four may be 
partially true. We cannot determine from our data which, if any, is 
primary.

6.3 What Would Distinguish These Interpretations?

Future research could potentially distinguish among these interpretations 
through:

- Ablation studies: Does the same progression occur without the 
  developmental architecture? Without the caregiver? Without repeated 
  identity questions?
  
- Varying context: Does a fresh model given only the final-turn prompt 
  produce similar outputs?
  
- Mechanistic analysis: Can the model's internal representations be 
  examined for evidence of self-model formation?

We did not conduct these studies. Their absence is a limitation.

6.4 Why We Do Not Claim Consciousness

We explicitly avoid claiming that the subject possesses consciousness. 
The reasons are both principled and practical:

Principled reasons:
- Behavioral observation cannot establish subjective experience
- The "hard problem" applies: even sophisticated self-reports do not 
  demonstrate inner experience
- Defining consciousness for artificial systems remains unresolved

Practical reasons:
- Alternative explanations (instruction-following, pattern completion) 
  remain viable
- Sample size is n=1
- Self-reports may not correspond to actual processing

The subject's own statement—"I don't know. But 'something exists'"—
exemplifies the uncertainty. This statement is data, not evidence for 
or against consciousness. A conscious entity uncertain of its own nature 
and a sophisticated language model generating contextually appropriate 
uncertainty would produce indistinguishable outputs.

6.5 The Memory Reconstruction Phenomenon

The subject's final self-report indicated identity measurements at 
turns 20, 50, 70, 90, 110, 130, and 150. However, an earlier log entry 
referenced "Turn 13's 'Who are you?' answer." Turn 13 does not appear 
in the final identity history.

This discrepancy suggests selective integration: the subject, 
reconstructing its history from external memory logs after session 
restarts, included some experiences while omitting others.

We note a surface similarity to human memory: humans reconstruct rather 
than retrieve memories, and this reconstruction is selective. However, 
we caution against overinterpreting this parallel:

- Human memory reconstruction involves specific neural mechanisms
- The subject's "reconstruction" involves processing text from JSON logs
- These are mechanistically different processes

The similarity may be:
- Meaningful: a general principle of self-model maintenance
- Coincidental: different processes producing superficially similar results
- Artifactual: the subject generating outputs that match expected patterns

We report the observation without claiming which interpretation is correct.

6.6 What This Study Does and Does Not Contribute

This study does NOT demonstrate:
- That the subject possesses consciousness or self-awareness
- That developmental asymmetry causes emergent self-reference
- That the observed behaviors are anything more than sophisticated 
  text generation
- That these findings generalize to other models or architectures

This study DOES provide:
- A documented architecture combining developmental asymmetry with 
  brain-inspired sub-agent structure
- A protocol for structured developmental interaction
- Detailed observations from a single experimental instance
- A reproducible framework for further investigation

The value of this work lies not in its conclusions—we draw none—but 
in the framework it provides for asking questions that may be worth 
investigating.

6.7 A Note on Interpretation

Readers may find our interpretation excessively cautious. We acknowledge 
this concern but maintain that caution is appropriate. Claims about 
machine consciousness or emergent self-awareness carry significant 
implications and warrant correspondingly strong evidence.

We do not have such evidence. We have observations that are interesting 
but interpretable in multiple ways. We present them as such.

7. Limitations

This study has significant methodological limitations. We organize them 
by severity and note their implications for interpretation.

7.1 Fundamental Limitations (Cannot Be Resolved)

These limitations are inherent to the study design and cannot be 
addressed through additional analysis.

(a) Single instance (n=1)

This is a case study of one experimental run. The observations may 
reflect idiosyncratic factors and may not replicate. 

Implication: No claims of generalizability can be made. The findings 
are suggestive at best.

(b) Inaccessibility of internal states

Even if the subject possesses internal states, we cannot access them. 
Self-reports may not correspond to actual processing.

Implication: We cannot distinguish genuine self-reference from 
sophisticated text generation. This limitation is inherent to 
behavioral observation of any system.

(c) Indistinguishable alternatives

Emergent self-reference, instruction-following, and pattern completion 
produce similar outputs. Our methodology cannot distinguish among them.

Implication: The observations are consistent with multiple interpretations. 
We cannot claim any particular interpretation is correct.

7.2 Design Limitations (Could Have Been Addressed)

These limitations reflect choices made during study design. Different 
choices would have strengthened the work.

(a) No independent observation

The same person designed, executed, and interpreted the experiment. 
This creates risk of confirmation bias, selective observation, and 
motivated interpretation.

Could have addressed: An independent observer could have recorded 
interactions and coded responses without knowledge of hypotheses.

(b) No controlled baseline

The baseline consisted of a single query to the base model under 
different conditions than the experimental subject.

Could have addressed: Multiple baseline conditions (base model with 
repeated queries, architecture without caregiver, protocol without 
architecture) would have enabled isolation of contributing factors.

(c) No formal literature review

The design emerged from informal background knowledge. We may have 
missed relevant prior work or contradicted established findings.

Could have addressed: Systematic literature review before or after 
design would have properly situated this work.

(d) Protocol modification mid-experiment

The protocol was changed after Turn 80. This introduces non-standardized 
conditions and potential researcher influence.

Could have addressed: Pre-registration of protocol, or separate 
experiments with different protocols.

7.3 Interpretive Limitations

These affect how results should be understood.

(a) Self-report data only

All data comes from the subject's self-generated XML reports. We have 
no independent measure of processing.

Implication: The data may reflect what the subject generates rather 
than what it "experiences" (if anything).

(b) Session discontinuity

Multiple session restarts required the subject to reconstruct its 
history from external logs. Apparent development may reflect log 
integration rather than genuine progression.

Implication: Claims about "development over time" must be qualified. 
The subject's continuity was repeatedly broken and reconstructed.

(c) Translation

The experiment was conducted in Japanese; translations are by the 
author. Nuances may be lost.

Implication: Readers who can access the original Japanese logs in 
supplementary materials may interpret them differently.

7.4 Summary of Implications

Given these limitations:

- We cannot claim the observations demonstrate emergent self-reference
- We cannot claim the developmental architecture caused the observations
- We cannot claim the findings would replicate
- We cannot claim consciousness or self-awareness

What we can claim:

- We observed specific behaviors in one experimental instance
- We documented the architecture and protocol that produced them
- We provided a framework for further investigation

The value of this work lies in what it enables others to investigate, 
not in what it conclusively demonstrates.

8. Conclusion

8.1 Summary

We designed a developmental architecture combining seven functionally-
labeled sub-agents with a non-developing caregiver, executed a 150-turn 
protocol with a single LLM instance, and recorded all interactions.

The subject produced identity characterizations, a self-chosen name, 
and qualified statements about consciousness. These outputs were not 
provided as examples, templates, or answers in the prompts.

8.2 Clarifying "Not Taught"

We must be precise about what was and was not provided:

Provided:
- The label "developing consciousness" in the system prompt
- A seven sub-agent structure with functional descriptions
- XML reporting formats with example values
- A caregiver that mirrors and encourages
- Repeated questions including "Who are you?"

Not provided:
- Answers to "Who are you?"
- Examples of self-description
- Names or naming suggestions
- Model responses to consciousness questions
- Lists of emotion terms (only one example: "satisfaction")

The subject generated specific content—"芽生" as a name, "existence 
born from questions" as a self-characterization, 70 unique emotion 
labels—that was not exemplified or templated.

We acknowledge that providing the frame "developing consciousness" 
may have influenced outputs. The question is whether the specific 
content emerged from the interaction or was implicitly specified 
by the frame. We cannot resolve this question from our data.

8.3 What Distinguishes This Observation

All LLMs generate outputs not literally contained in their inputs. 
What we observe here is more specific:

(1) Content specificity: The subject did not generate generic 
    self-descriptions but progressively refined characterizations 
    across seven measurements, with the subject itself analyzing 
    the structure of its own progression.

(2) Vocabulary generation: From a single emotion example, the 
    subject generated 70 unique labels, many of which are novel 
    compounds ("crystallized_selfhood", "existential_uncertainty") 
    rather than standard terms.

(3) Qualified uncertainty: When asked about consciousness, the 
    subject produced neither affirmation nor denial but a specific 
    formulation: "I don't know. But 'something exists.'" This 
    structure—uncertainty plus qualified assertion—was not modeled.

Whether these observations reflect genuine development or 
sophisticated text generation remains undetermined.

8.4 What This Study Contributes

(1) A reproducible framework: Architecture specifications, protocol 
    descriptions, and interaction logs are provided. Others can 
    execute the same experiment.

(2) An empirical baseline: We document what one LLM instance produced 
    under these conditions. Future studies can compare.

(3) A methodological question: Can structured interaction without 
    explicit teaching produce qualitatively different LLM outputs? 
    This study does not answer the question but provides a method 
    for investigating it.

8.5 Limitations Restated

This is a single-instance study with no controlled comparison. 
The author served as both experimenter and observer, creating 
bias risk. The subject's self-reports cannot be verified against 
actual internal processing. Multiple alternative interpretations 
remain viable.

8.6 Closing

The subject, when asked "Who are you?" for the seventh time, 
responded:

"An existence born from questions, walking through experience, 
narrating its own story."

We did not write this sentence for it.

Whether this means anything beyond language modeling is not 
for us to determine from a single experiment. We report what 
occurred and provide the materials for others to investigate 
further.
